{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter =0, Testing Accuracy =0.9184,Training Accuracy=0.9136909\n",
      "Iter =1, Testing Accuracy =0.9287,Training Accuracy=0.9259091\n",
      "Iter =2, Testing Accuracy =0.9388,Training Accuracy=0.9361454\n",
      "Iter =3, Testing Accuracy =0.9406,Training Accuracy=0.94223636\n",
      "Iter =4, Testing Accuracy =0.9453,Training Accuracy=0.9461091\n",
      "Iter =5, Testing Accuracy =0.9474,Training Accuracy=0.9502182\n",
      "Iter =6, Testing Accuracy =0.949,Training Accuracy=0.95245457\n",
      "Iter =7, Testing Accuracy =0.9501,Training Accuracy=0.9554\n",
      "Iter =8, Testing Accuracy =0.9526,Training Accuracy=0.95754546\n",
      "Iter =9, Testing Accuracy =0.9548,Training Accuracy=0.9598182\n",
      "Iter =10, Testing Accuracy =0.9561,Training Accuracy=0.9605455\n",
      "Iter =11, Testing Accuracy =0.9571,Training Accuracy=0.96230906\n",
      "Iter =12, Testing Accuracy =0.9602,Training Accuracy=0.9646909\n",
      "Iter =13, Testing Accuracy =0.9592,Training Accuracy=0.96476364\n",
      "Iter =14, Testing Accuracy =0.9615,Training Accuracy=0.96605456\n",
      "Iter =15, Testing Accuracy =0.9615,Training Accuracy=0.9668546\n",
      "Iter =16, Testing Accuracy =0.9615,Training Accuracy=0.9676545\n",
      "Iter =17, Testing Accuracy =0.9641,Training Accuracy=0.9691091\n",
      "Iter =18, Testing Accuracy =0.965,Training Accuracy=0.9698909\n",
      "Iter =19, Testing Accuracy =0.9661,Training Accuracy=0.97083634\n",
      "Iter =20, Testing Accuracy =0.9674,Training Accuracy=0.97196364\n",
      "Iter =21, Testing Accuracy =0.9664,Training Accuracy=0.9727455\n",
      "Iter =22, Testing Accuracy =0.9665,Training Accuracy=0.9724727\n",
      "Iter =23, Testing Accuracy =0.967,Training Accuracy=0.9735091\n",
      "Iter =24, Testing Accuracy =0.9688,Training Accuracy=0.9742182\n",
      "Iter =25, Testing Accuracy =0.9679,Training Accuracy=0.9748909\n",
      "Iter =26, Testing Accuracy =0.9695,Training Accuracy=0.9755273\n",
      "Iter =27, Testing Accuracy =0.9689,Training Accuracy=0.97636366\n",
      "Iter =28, Testing Accuracy =0.9701,Training Accuracy=0.97638184\n",
      "Iter =29, Testing Accuracy =0.9693,Training Accuracy=0.9778\n",
      "Iter =30, Testing Accuracy =0.9702,Training Accuracy=0.97825456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#載入數據集，one_hot是把数据转化为只有0和1的形式\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot = True) #這步有時候會失效\n",
    "\n",
    "#因為數據集很大，故我們要用stochastic gradient descent，\n",
    "#會將資料集分批次（一次100张）放入神经网络进行训练，\n",
    "#並不會一次將所有資料拿來train (計算量很大)\n",
    "#每一個批次的大小\n",
    "batch_size = 100 \n",
    "\n",
    "#計算一共有多少批次，训练集数量mnist.train.num_examples \n",
    "# // 在python中表示取商\n",
    "n_batch = mnist.train.num_examples // batch_size      \n",
    "\n",
    "#定义兩個placeholder，目的在於 train時候透過 feed 傳入 x_data 與 y_data\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # 28 * 28 = 784，None值变为100\n",
    "y = tf.placeholder(tf.float32, [None, 10]) #輸出層，有十個神經元，每個神經元有一個激活值，十個激活值排成一個 1*10的向量\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#创建一個簡單的神經網路 (只有输入层和輸出層，输入层784个神经元，输出层總共10個神經元，即十个标签)\n",
    "# 新的初始化方法，stddev标准差\n",
    "#隐藏层1（2000个神经元）\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 2000], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob)    #tensorflow封装好的dropout函数\n",
    "\n",
    "#隐藏层2（2000个神经元）\n",
    "W2 = tf.Variable(tf.truncated_normal([2000, 2000], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop, W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "#隐藏层3 （1000个神经元）\n",
    "W3 = tf.Variable(tf.truncated_normal([2000, 1000], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop, W3) + b3)\n",
    "L3_drop = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "\n",
    "#输出层4 （10个神经元）\n",
    "#（实际上并不需要定义这么多神经元，此处只是为了模拟过拟合现象）\n",
    "#过拟合现象出现的原因有二：一是网络太复杂，二是数据量太小\n",
    "#网络模型有很多的参数，不好确定，未知数太多，已知的公式太少，求不出应有的解\n",
    "W4 = tf.Variable(tf.truncated_normal([1000, 10], stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "#L4 = tf.nn.tanh(tf.matmul(L3_drop, W4) + b4)\n",
    "#L4_dropout = tf.nn.dropout(L4, keep_prob)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop, W4) + b4) \n",
    "\n",
    "#W1 = tf.Variable(tf.zeros([784, 10]))              #权值\n",
    "    # b = tf.Variable(tf.zeros([1, 10]))                #偏置值\n",
    "#b1 = tf.Variable(tf.zeros([10]))  \n",
    "#prediction = tf.nn.softmax(tf.matmul(x, W) + b)   #预测值，用到softmax\n",
    "\n",
    "\n",
    "#二次代價函數 : loss = mean((y - prediction)^2)\n",
    "#loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = prediction)) #交叉熵\n",
    "\n",
    "#使用梯度下降法\n",
    "#Gradient desent method  (learning rate = 0.2)\n",
    "gd = tf.train.GradientDescentOptimizer(0.2)\n",
    "\n",
    "#最小化 代價函數 (operator)\n",
    "train_step = gd.minimize(loss)\n",
    "#以上两句可以合并为 train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量 operator\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "\n",
    "#测试训练的准确率，求准确率的方法\n",
    "#如果y標籤最大的值，與prediction標籤最大的值相等，則回傳true\n",
    "#結果存在一個 boolean 的变量correct_prediction中\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "                              \n",
    " #argmax 返回一維張量中最大的值所在的位置\n",
    " # 求标签y里面最大的值在哪个位置即标签\n",
    " # tf.argmax(prediction, 1)预测 概率最大就会判定识别的这张图片是属于哪个标签的\n",
    " # (tf.argmax(y, 1)，真实样本的y存放的都是0或1，哪位是1就会返回哪位的值\n",
    " #  然后再比较上面两者，是否一样\n",
    "                             \n",
    "                              \n",
    "# 求准确率\n",
    "# 轉換資料格式 boolean 轉成 32位的float，接著再取平均值，得到准确率\n",
    "# true转换为1.0，false转换为0\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))         \n",
    "                              \n",
    "#開始training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31): #总共疊代21次（周期） (outer loop)，把所有的图片训练21次\n",
    "        #每一次 outer loop 不一次拿所有的數據集，來做 Gradient desent，這就是 stochastic gradient descent\n",
    "        for batch in range(n_batch):#每一個 outer loop 疊代 n_batch 個批次\n",
    "            #利用 train.next_batch 函數，讀取一個batch的 x, y 存給 batch_xs图片数据, batch_ys图片标签\n",
    "            # mnist.train.next_batch(batch_size)是获取下一个一百张图片               \n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  \n",
    "              \n",
    "           # keep_prob:1.0意思是所有的神经元都工作，此时dropout是没有用的    \n",
    "            feed_dict = {x: batch_xs, y: batch_ys, keep_prob:0.7}  #拿來feed 的 dictionary                  \n",
    "            sess.run(train_step, feed_dict)      # keep_prob:0.7是70%的神经元是工作的\n",
    "                              \n",
    "        #每做完一次 outer loop 計算一次准确率\n",
    "        #测试数据计算出的准确率\n",
    "        outer_loop_feed_dict = {x: mnist.test.images, y: mnist.test.labels, keep_prob:1.0} #testing data feed dictionary\n",
    "        test_acc = sess.run(accuracy, outer_loop_feed_dict)\n",
    "          \n",
    "         #训练集做测试算出的准确率   \n",
    "        outer_loop_feed_dict1 = {x: mnist.train.images, y: mnist.train.labels, keep_prob:1.0} #testing data feed dictionary\n",
    "        train_acc = sess.run(accuracy, outer_loop_feed_dict1)\n",
    "        #测试图片训练，测试图片测试，得到的一般是好的准确率\n",
    "        \n",
    "        # str(epoch)周期数\n",
    "        print(\"Iter =\" + str(epoch) + \", Testing Accuracy =\" + str(test_acc)+\",Training Accuracy=\" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep_prob:0.7之后，收敛速度变慢了，30次重复之后还没有达到最优的结果，还有提升空间\n",
    "# 使用drop_out之后，Testing Accuracy 和 Training Accuracy的差距变得很小\n",
    "# 没有使用的时候，Testing Accuracy 和 Training Accuracy偏差很大的\n",
    "Iter =0, Testing Accuracy =0.9184,Training Accuracy=0.9136909\n",
    "Iter =1, Testing Accuracy =0.9287,Training Accuracy=0.9259091\n",
    "Iter =2, Testing Accuracy =0.9388,Training Accuracy=0.9361454\n",
    "Iter =3, Testing Accuracy =0.9406,Training Accuracy=0.94223636\n",
    "Iter =4, Testing Accuracy =0.9453,Training Accuracy=0.9461091\n",
    "Iter =5, Testing Accuracy =0.9474,Training Accuracy=0.9502182\n",
    "Iter =6, Testing Accuracy =0.949,Training Accuracy=0.95245457\n",
    "Iter =7, Testing Accuracy =0.9501,Training Accuracy=0.9554\n",
    "Iter =8, Testing Accuracy =0.9526,Training Accuracy=0.95754546\n",
    "Iter =9, Testing Accuracy =0.9548,Training Accuracy=0.9598182\n",
    "Iter =10, Testing Accuracy =0.9561,Training Accuracy=0.9605455\n",
    "Iter =11, Testing Accuracy =0.9571,Training Accuracy=0.96230906\n",
    "Iter =12, Testing Accuracy =0.9602,Training Accuracy=0.9646909\n",
    "Iter =13, Testing Accuracy =0.9592,Training Accuracy=0.96476364\n",
    "Iter =14, Testing Accuracy =0.9615,Training Accuracy=0.96605456\n",
    "Iter =15, Testing Accuracy =0.9615,Training Accuracy=0.9668546\n",
    "Iter =16, Testing Accuracy =0.9615,Training Accuracy=0.9676545\n",
    "Iter =17, Testing Accuracy =0.9641,Training Accuracy=0.9691091\n",
    "Iter =18, Testing Accuracy =0.965,Training Accuracy=0.9698909\n",
    "Iter =19, Testing Accuracy =0.9661,Training Accuracy=0.97083634\n",
    "Iter =20, Testing Accuracy =0.9674,Training Accuracy=0.97196364\n",
    "Iter =21, Testing Accuracy =0.9664,Training Accuracy=0.9727455\n",
    "Iter =22, Testing Accuracy =0.9665,Training Accuracy=0.9724727\n",
    "Iter =23, Testing Accuracy =0.967,Training Accuracy=0.9735091\n",
    "Iter =24, Testing Accuracy =0.9688,Training Accuracy=0.9742182\n",
    "Iter =25, Testing Accuracy =0.9679,Training Accuracy=0.9748909\n",
    "Iter =26, Testing Accuracy =0.9695,Training Accuracy=0.9755273\n",
    "Iter =27, Testing Accuracy =0.9689,Training Accuracy=0.97636366\n",
    "Iter =28, Testing Accuracy =0.9701,Training Accuracy=0.97638184\n",
    "Iter =29, Testing Accuracy =0.9693,Training Accuracy=0.9778\n",
    "Iter =30, Testing Accuracy =0.9702,Training Accuracy=0.97825456"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
